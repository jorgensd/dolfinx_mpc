name: Test MPC

on:
  # Trigger tests on push
  workflow_dispatch:
  workflow_call:
  pull_request:
    branches:
      - main
  schedule:
    # '*' is a special character in YAML, so string must be quoted
    - cron: "0 8 * * *"

jobs:
  build:
    runs-on: ubuntu-latest
    container: ghcr.io/fenics/dolfinx/dev-env:current-mpich

    strategy:
      matrix:
        build_mode: [Release, Debug]
        petsc_arch:
          [
            linux-gnu-complex128-32,
            linux-gnu-complex64-32,
            linux-gnu-real64-32,
            linux-gnu-real32-32,
          ]
        # Due to: https://gitlab.com/petsc/petsc/-/issues/1288
        CXX: [c++]
        #, clang++]
        CC: [cc]
        #, clang]
        # exclude:
        #   - CC: cc
        #     CXX: clang++
        #   - CC: clang
        #     CXX: c++
    env:
      DOLFINX_BRANCH: main
      BASIX_BRANCH: main
      UFL_BRANCH: main
      FFCX_BRANCH: main

      CC: ${{ matrix.CC }}
      CXX: ${{ matrix.CXX }}
      PETSC_ARCH: "${{ matrix.petsc_arch }}"
      OMPI_ALLOW_RUN_AS_ROOT: 1
      OMPI_ALLOW_RUN_AS_ROOT_CONFIRM: 1
      OMPI_MCA_rmaps_base_oversubscribe: 1
      OMPI_MCA_plm: isolated
      OMPI_MCA_btl_vader_single_copy_mechanism: none
      OMPI_MCA_mpi_yield_when_idle: 1
      OMPI_MCA_hwloc_base_binding_policy: none
      HDF5_MPI: "ON"
      HDF5_DIR: "/usr/local/"
      MPC_BUILD_MODE: ${{ matrix.build_mode }}
      MPC_CMAKE_CXX_FLAGS: "-Wall -Werror -g -pedantic -Ofast -march=native"
      PYTHONPATH: "/usr/local/dolfinx-${PETSC_TYPE}/lib/python3.12/dist-packages:/usr/local/lib"
      LD_LIBRARY_PATH: "/usr/local/petsc/${PETSC_ARCH}/lib/:/usr/local"
      DEB_PYTHON_INSTALL_LAYOUT: deb_system
    steps:
      - uses: actions/checkout@v4

      - name: Install clang
        if: ${{ matrix.CC }} == "clang"
        run: |
          apt-get update
          apt-get install -y clang

      - name: upgrade pip
        run: python3 -m pip install  --upgrade setuptools pip

      - name: Check formatting
        run: |
          python3 -m pip install  ruff
          ruff check
          ruff format

      - name: Check typing
        run: |
          python3 -m pip install  mypy
          cd python
          python3 -m mypy . --exclude=build

      - name: Install h5py
        run: |
          python3 -m pip install --no-build-isolation  --no-cache-dir --no-binary=h5py h5py

      - name: Install DOLFINx
        uses: jorgensd/actions/install-dolfinx@v0.4
        with:
          dolfinx: ${{ env.DOLFINX_BRANCH }}
          ufl: ${{ env.UFL_BRANCH }}
          basix: ${{ env.BASIX_BRANCH }}
          ffcx: ${{ env.FFCX_BRANCH }}
          petsc_arch: ${{ env.PETSC_ARCH }}
      - name: Restrict CFFI
        run:
           python3 -m pip install --no-build-isolation "cffi<1.17"

      - name: Install DOLFINx-MPC (C++)
        run: |
          cmake -G Ninja -B build-dir -DCMAKE_BUILD_TYPE=${MPC_BUILD_MODE} -DCMAKE_CXX_FLAGS="${MPC_CMAKE_CXX_FLAGS}" -S cpp/
          cmake --build build-dir --parallel 3
          cmake --install build-dir

      - name: Install DOLFINx-MPC (Python)
        run: python3 -m pip -v install  --config-settings=cmake.build-type=${MPC_BUILD_MODE} --no-build-isolation  -e python/[test]

      - name: Run tests (serial)
        run: coverage run --rcfile=.coveragerc -m mpi4py -m pytest python/tests/ -vs

      - name: Run tests (2 processes)
        run: mpirun -n 2 coverage run --rcfile=.coveragerc -m mpi4py -m pytest python/tests/ -vs

      - name: Run tests (3 processes)
        run: mpirun -n 3 coverage run --rcfile=.coveragerc -m mpi4py -m pytest python/tests/

      - name: Run tests (4 processes)
        run: mpirun -n 4 coverage run --rcfile=.coveragerc -m mpi4py -m pytest python/tests/

      - name: Run benchmarks
        run: |
          mpirun -n 2 coverage run --rcfile=.coveragerc -m mpi4py python/benchmarks/bench_periodic.py --nref=2 --tet --gamg --timings
          mpirun -n 2 coverage run --rcfile=.coveragerc -m mpi4py python/benchmarks/bench_elasticity_edge.py --nref=2 --gamg --timings
          mpirun -n 2 coverage run --rcfile=.coveragerc -m mpi4py python/benchmarks/bench_contact_3D.py

      - name: Run demos (serial)
        run: |
          coverage run --rcfile=.coveragerc python/demos/demo_elasticity.py
          coverage run --rcfile=.coveragerc python/demos/demo_periodic_geometrical.py
          coverage run --rcfile=.coveragerc python/demos/demo_stokes.py
          coverage run --rcfile=.coveragerc python/demos/demo_periodic3d_topological.py
          coverage run --rcfile=.coveragerc python/demos/demo_elasticity_disconnect_2D.py
          coverage run --rcfile=.coveragerc python/demos/demo_elasticity_disconnect.py
          coverage run --rcfile=.coveragerc python/demos/demo_periodic_gep.py

      - name: Run demos (parallel)
        run: |
          mpirun -n 2 coverage run --rcfile=.coveragerc -m mpi4py python/demos/demo_elasticity.py
          mpirun -n 2 coverage run --rcfile=.coveragerc -m mpi4py python/demos/demo_periodic_geometrical.py
          mpirun -n 2 coverage run --rcfile=.coveragerc -m mpi4py python/demos/demo_stokes.py
          mpirun -n 2 coverage run --rcfile=.coveragerc -m mpi4py python/demos/demo_periodic3d_topological.py
          mpirun -n 2 coverage run --rcfile=.coveragerc -m mpi4py python/demos/demo_elasticity_disconnect_2D.py
          mpirun -n 2 coverage run --rcfile=.coveragerc -m mpi4py python/demos/demo_elasticity_disconnect.py
          mpirun -n 2 coverage run --rcfile=.coveragerc -m mpi4py python/demos/demo_periodic_gep.py

      - name: Run contact demos 2D (serial)
        run: |
          coverage run --rcfile=.coveragerc python/demos/demo_contact_2D.py --theta 0 --timing
          coverage run --rcfile=.coveragerc python/demos/demo_contact_2D.py --theta 1.05 --timing
          coverage run --rcfile=.coveragerc python/demos/demo_contact_2D.py --gmsh --theta 0 --timing
          coverage run --rcfile=.coveragerc python/demos/demo_contact_2D.py --gmsh --theta 1.05 --timing
          coverage run --rcfile=.coveragerc python/demos/demo_contact_2D.py --quad --gmsh --theta 0 --timing
          coverage run --rcfile=.coveragerc python/demos/demo_contact_2D.py --quad --gmsh --theta 1.05 --timing

      - name: Run contact demos 2D (parallel)
        run: |
          mpirun -n 2 coverage run --rcfile=.coveragerc -m mpi4py python/demos/demo_contact_2D.py --theta 0 --timing
          mpirun -n 2 coverage run --rcfile=.coveragerc -m mpi4py python/demos/demo_contact_2D.py --theta 1.05 --timing
          mpirun -n 2 coverage run --rcfile=.coveragerc -m mpi4py python/demos/demo_contact_2D.py --gmsh --theta 0 --timing
          mpirun -n 2 coverage run --rcfile=.coveragerc -m mpi4py python/demos/demo_contact_2D.py --gmsh --theta 1.05 --timing
          mpirun -n 2 coverage run --rcfile=.coveragerc -m mpi4py python/demos/demo_contact_2D.py --quad --gmsh --theta 0 --timing
          mpirun -n 2 coverage run --rcfile=.coveragerc -m mpi4py python/demos/demo_contact_2D.py --quad --gmsh --theta 1.05 --timing

      - name: Run contact demos 3D (serial)
        run: |
          coverage run --rcfile=.coveragerc python/demos/demo_contact_3D.py --theta 0 --timing
          coverage run --rcfile=.coveragerc python/demos/demo_contact_3D.py --theta 1.05 --timing
          coverage run --rcfile=.coveragerc python/demos/demo_contact_3D.py --gmsh --theta 0 --timing
          coverage run --rcfile=.coveragerc python/demos/demo_contact_3D.py --gmsh --theta 1.05 --timing
          coverage run --rcfile=.coveragerc python/demos/demo_contact_3D.py --gmsh --no-slip --theta 0 --timing
          coverage run --rcfile=.coveragerc python/demos/demo_contact_3D.py --gmsh --no-slip --theta 1.05 --timing
          coverage run --rcfile=.coveragerc python/demos/demo_contact_3D.py --gmsh --no-slip --hex --theta 0 --timing
          coverage run --rcfile=.coveragerc python/demos/demo_contact_3D.py --gmsh --no-slip --hex --theta 1.05 --timing

      - name: Run contact demos 3D (parallel)
        run: |
          mpirun -n 2 coverage run --rcfile=.coveragerc -m mpi4py python/demos/demo_contact_3D.py --theta 0 --timing
          mpirun -n 2 coverage run --rcfile=.coveragerc -m mpi4py python/demos/demo_contact_3D.py --theta 1.05 --timing
          mpirun -n 2 coverage run --rcfile=.coveragerc -m mpi4py python/demos/demo_contact_3D.py --gmsh --theta 0 --timing
          mpirun -n 2 coverage run --rcfile=.coveragerc -m mpi4py python/demos/demo_contact_3D.py --gmsh --theta 1.05 --timing
          mpirun -n 2 coverage run --rcfile=.coveragerc -m mpi4py python/demos/demo_contact_3D.py --gmsh --no-slip --theta 0 --timing
          mpirun -n 2 coverage run --rcfile=.coveragerc -m mpi4py python/demos/demo_contact_3D.py --gmsh --no-slip --theta 1.05 --timing
          mpirun -n 2 coverage run --rcfile=.coveragerc -m mpi4py python/demos/demo_contact_3D.py --gmsh --no-slip --hex --theta 0 --timing
          mpirun -n 2 coverage run --rcfile=.coveragerc -m mpi4py python/demos/demo_contact_3D.py --gmsh --no-slip --hex --theta 1.05 --timing

      - name: Combine coverage reports
        run: |
          coverage combine
          coverage report -m
          coverage html

      - name: Upload coverage report as artifact
        if: matrix.build_mode == 'Release' && matrix.petsc_arch == 'linux-gnu-real64-32' && matrix.CC == 'cc' && matrix.CXX == 'c++'
        uses: actions/upload-artifact@v4
        with:
          name: code-coverage-report
          path: htmlcov
          if-no-files-found: error
