name: Test MPC

on:
  # Trigger tests on push
  workflow_dispatch:
  workflow_call:
  pull_request:
    branches:
      - main
  schedule:
    # '*' is a special character in YAML, so string must be quoted
    - cron: "0 8 * * *"


jobs:
  build:
    if: "!(contains(github.event.head_commit.message, '[ci skip]') || contains(github.event.head_commit.message, '[skip ci]'))"
    runs-on: ubuntu-latest
    container: ghcr.io/fenics/test-env:nightly-mpich

    strategy:
      matrix:
        build_mode: [Release, Debug]
        petsc_arch: [real, complex]
        # Due to: https://gitlab.com/petsc/petsc/-/issues/1288
        CXX: [c++]
        #, clang++]
        CC: [cc] 
        #, clang]
        # exclude:
        #   - CC: cc
        #     CXX: clang++
        #   - CC: clang
        #     CXX: c++
    env:
      DOLFINX_BRANCH: "main"
      BASIX_BRANCH: "main"
      UFL_BRANCH:  "main"
      FFCX_BRANCH: "main"
      CC: ${{ matrix.CC }}
      CXX: ${{ matrix.CXX }}
      PETSC_ARCH: "linux-gnu-${{ matrix.petsc_arch }}-32"
      OMPI_ALLOW_RUN_AS_ROOT: 1
      OMPI_ALLOW_RUN_AS_ROOT_CONFIRM: 1
      OMPI_MCA_rmaps_base_oversubscribe: 1
      OMPI_MCA_plm: isolated
      OMPI_MCA_btl_vader_single_copy_mechanism: none
      OMPI_MCA_mpi_yield_when_idle: 1
      OMPI_MCA_hwloc_base_binding_policy: none
      HDF5_MPI: "ON"
      HDF5_DIR: "/usr/local/"
      MPC_BUILD_MODE: ${{ matrix.build_mode }}
      MPC_CMAKE_CXX_FLAGS: "-Wall -Werror -g -pedantic -Ofast -march=native"
      PYTHONPATH: "/usr/local/dolfinx-${PETSC_TYPE}/lib/python3.10/dist-packages:/usr/local/lib"
      LD_LIBRARY_PATH: "/usr/local/petsc/${PETSC_ARCH}/lib/:/usr/local"
      DEB_PYTHON_INSTALL_LAYOUT: deb_system
    steps:
      - uses: actions/checkout@v3

      - name: Install clang
        if: ${{ matrix.CC }} == "clang"
        run: |
          apt-get update
          apt-get install -y clang

      - name: upgrade pip
        run: python3 -m pip install --upgrade setuptools pip

      - name: Flake8 code
        run: flake8 python/

      - name: Mypy check
        run: |
           python3 -m pip install mypy
           cd python
           python3 -m mypy . --exclude=build

      - name: Install h5py (https://github.com/h5py/h5py/issues/2222)
        run: |
          python3 -m pip install mpi4py cython numpy
          python3 -m pip install --no-cache-dir --no-binary=h5py h5py  --no-build-isolation

     
      - name: Install DOLFINx
        uses: ./.github/actions/install-dolfinx
        with:
          dolfinx: ${{ env.DOLFINX_BRANCH }}
          ufl: ${{ env.UFL_BRANCH }}
          basix: ${{ env.BASIX_BRANCH }}
          ffcx: ${{ env.FFCX_BRANCH }}
          petsc_arch: ${{ env.PETSC_ARCH }}

      - name: Install DOLFINx-MPC (C++)
        run: |
          cmake -G Ninja -B build-dir -DCMAKE_BUILD_TYPE=${MPC_BUILD_MODE} -DCMAKE_CXX_FLAGS="${MPC_CMAKE_CXX_FLAGS}" -S cpp/
          cmake --build build-dir --parallel 3
          cmake --install build-dir

      - name: Install DOLFINx-MPC (Python)
        run: CXX_FLAGS="${MPC_CMAKE_CXX_FLAGS}" python3 -m pip -v install python/[test]

      - name: Run tests (serial)
        run: coverage run --rcfile=.coveragerc -m mpi4py -m pytest python/tests/

      - name: Run tests (2 processes)
        run: mpirun -n 2 coverage run --rcfile=.coveragerc -m mpi4py -m pytest python/tests/ -vs

      - name: Run tests (3 processes)
        run: mpirun -n 3 coverage run --rcfile=.coveragerc -m mpi4py -m pytest python/tests/

      - name: Run tests (4 processes)
        run: mpirun -n 4 coverage run --rcfile=.coveragerc -m mpi4py -m pytest python/tests/

      - name: Run benchmarks
        run: |
          mpirun -n 2 coverage run --rcfile=.coveragerc -m mpi4py python/benchmarks/bench_periodic.py --nref=2 --tet --gamg --timings
          mpirun -n 2 coverage run --rcfile=.coveragerc -m mpi4py python/benchmarks/bench_elasticity_edge.py --nref=2 --gamg --timings
          mpirun -n 2 coverage run --rcfile=.coveragerc -m mpi4py python/benchmarks/bench_contact_3D.py

      - name: Run demos (serial)
        run: |
          mkdir -p meshes
          mkdir -p results
          coverage run --rcfile=.coveragerc python/demos/demo_elasticity.py
          coverage run --rcfile=.coveragerc python/demos/demo_periodic_geometrical.py
          coverage run --rcfile=.coveragerc python/demos/demo_stokes.py
          coverage run --rcfile=.coveragerc python/demos/demo_periodic3d_topological.py
          coverage run --rcfile=.coveragerc python/demos/demo_elasticity_disconnect_2D.py
          coverage run --rcfile=.coveragerc python/demos/demo_elasticity_disconnect.py
          coverage run --rcfile=.coveragerc python/demos/demo_periodic_gep.py

      - name: Run demos (parallel)
        run: |
          mpirun -n 2 coverage run --rcfile=.coveragerc -m mpi4py python/demos/demo_elasticity.py
          mpirun -n 2 coverage run --rcfile=.coveragerc -m mpi4py python/demos/demo_periodic_geometrical.py
          mpirun -n 2 coverage run --rcfile=.coveragerc -m mpi4py python/demos/demo_stokes.py
          mpirun -n 2 coverage run --rcfile=.coveragerc -m mpi4py python/demos/demo_periodic3d_topological.py
          mpirun -n 2 coverage run --rcfile=.coveragerc -m mpi4py python/demos/demo_elasticity_disconnect_2D.py
          mpirun -n 2 coverage run --rcfile=.coveragerc -m mpi4py python/demos/demo_elasticity_disconnect.py
          mpirun -n 2 coverage run --rcfile=.coveragerc -m mpi4py python/demos/demo_periodic_gep.py

      - name: Run contact demos 2D (serial)
        run: |
          coverage run --rcfile=.coveragerc python/demos/demo_contact_2D.py --theta 0 --timing
          coverage run --rcfile=.coveragerc python/demos/demo_contact_2D.py --theta 1.05 --timing
          coverage run --rcfile=.coveragerc python/demos/demo_contact_2D.py --gmsh --theta 0 --timing
          coverage run --rcfile=.coveragerc python/demos/demo_contact_2D.py --gmsh --theta 1.05 --timing
          coverage run --rcfile=.coveragerc python/demos/demo_contact_2D.py --quad --gmsh --theta 0 --timing
          coverage run --rcfile=.coveragerc python/demos/demo_contact_2D.py --quad --gmsh --theta 1.05 --timing

      - name: Run contact demos 2D (parallel)
        run: |
          mpirun -n 2 coverage run --rcfile=.coveragerc -m mpi4py python/demos/demo_contact_2D.py --theta 0 --timing
          mpirun -n 2 coverage run --rcfile=.coveragerc -m mpi4py python/demos/demo_contact_2D.py --theta 1.05 --timing
          mpirun -n 2 coverage run --rcfile=.coveragerc -m mpi4py python/demos/demo_contact_2D.py --gmsh --theta 0 --timing
          mpirun -n 2 coverage run --rcfile=.coveragerc -m mpi4py python/demos/demo_contact_2D.py --gmsh --theta 1.05 --timing
          mpirun -n 2 coverage run --rcfile=.coveragerc -m mpi4py python/demos/demo_contact_2D.py --quad --gmsh --theta 0 --timing
          mpirun -n 2 coverage run --rcfile=.coveragerc -m mpi4py python/demos/demo_contact_2D.py --quad --gmsh --theta 1.05 --timing

      - name: Run contact demos 3D (serial)
        run: |
          coverage run --rcfile=.coveragerc python/demos/demo_contact_3D.py --theta 0 --timing
          coverage run --rcfile=.coveragerc python/demos/demo_contact_3D.py --theta 1.05 --timing
          coverage run --rcfile=.coveragerc python/demos/demo_contact_3D.py --gmsh --theta 0 --timing
          coverage run --rcfile=.coveragerc python/demos/demo_contact_3D.py --gmsh --theta 1.05 --timing
          coverage run --rcfile=.coveragerc python/demos/demo_contact_3D.py --gmsh --no-slip --theta 0 --timing
          coverage run --rcfile=.coveragerc python/demos/demo_contact_3D.py --gmsh --no-slip --theta 1.05 --timing
          coverage run --rcfile=.coveragerc python/demos/demo_contact_3D.py --gmsh --no-slip --hex --theta 0 --timing
          coverage run --rcfile=.coveragerc python/demos/demo_contact_3D.py --gmsh --no-slip --hex --theta 1.05 --timing

      - name: Run contact demos 3D (parallel)
        run: |
          mpirun -n 2 coverage run --rcfile=.coveragerc -m mpi4py python/demos/demo_contact_3D.py --theta 0 --timing
          mpirun -n 2 coverage run --rcfile=.coveragerc -m mpi4py python/demos/demo_contact_3D.py --theta 1.05 --timing
          mpirun -n 2 coverage run --rcfile=.coveragerc -m mpi4py python/demos/demo_contact_3D.py --gmsh --theta 0 --timing
          mpirun -n 2 coverage run --rcfile=.coveragerc -m mpi4py python/demos/demo_contact_3D.py --gmsh --theta 1.05 --timing
          mpirun -n 2 coverage run --rcfile=.coveragerc -m mpi4py python/demos/demo_contact_3D.py --gmsh --no-slip --theta 0 --timing
          mpirun -n 2 coverage run --rcfile=.coveragerc -m mpi4py python/demos/demo_contact_3D.py --gmsh --no-slip --theta 1.05 --timing
          mpirun -n 2 coverage run --rcfile=.coveragerc -m mpi4py python/demos/demo_contact_3D.py --gmsh --no-slip --hex --theta 0 --timing
          mpirun -n 2 coverage run --rcfile=.coveragerc -m mpi4py python/demos/demo_contact_3D.py --gmsh --no-slip --hex --theta 1.05 --timing
    
      - name: Combine coverage reports
        run: |
          coverage combine
          coverage report -m
          coverage html

      - name: Upload coverage report as artifact
        if: matrix.build_mode == 'release' && matrix.petsc_arch == 'real' && matrix.CC == 'cc' && matrix.CXX == 'c++'
        uses: actions/upload-artifact@v3
        with:
          name: code-coverage-report
          path: htmlcov
          if-no-files-found: error
